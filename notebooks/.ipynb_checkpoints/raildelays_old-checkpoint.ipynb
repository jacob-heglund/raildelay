{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:58:57.709648Z",
     "start_time": "2020-02-27T21:58:57.702909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jacobheglund/dev/raildelays\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import collections\n",
    "import networkx as nx\n",
    "\n",
    "import pdb\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "os.chdir(\"/home/jacobheglund/dev/raildelays\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train-Based Node Formulation\n",
    "We're not doing this for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T19:37:57.461696Z",
     "start_time": "2020-02-27T19:37:57.453127Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_nodes(df, time_delta=20, stop_delta=10):\n",
    "    # takes a df and clusters rows based off of specific features and thresholds, these clusters are nodes on our train network graph\n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    df_tmp = df_tmp.loc[df_tmp[\"arrival_sched\"] == \"starting\"]\n",
    "    df_tmp[\"node_idx\"] = -1\n",
    "    # if node_idx == -1, the row is not yet associated with a node\n",
    "    df_tmp[\"node_idx\"] = -1\n",
    "    df_save = pd.DataFrame(columns=df_tmp.columns)\n",
    "    node_count = 0\n",
    "    #TODO make this go to 0\n",
    "    while len(df_tmp) > 0:        \n",
    "        # init the first row of df_tmp as the current node\n",
    "        df_tmp.at[0, \"node_idx\"] = node_count\n",
    "        node_row = df_tmp[0:1]\n",
    "        df_save = df_save.append(node_row)\n",
    "        node_stops = node_row[\"stops_in_journey\"].item()\n",
    "        \n",
    "        time_radius = pd.Timedelta(time_delta, unit=\"m\")\n",
    "        node_depart_time = pd.to_datetime(node_row[\"departure_sched\"], format=\"%H%M\").item()\n",
    "        t1,t2 = node_depart_time - time_radius, node_depart_time + time_radius\n",
    "        curr_node_count = 1\n",
    "        for j in range(len(df_tmp)):\n",
    "            # check rows to see if they are associated with the current node\n",
    "            curr_row = df_tmp[j:j+1]\n",
    "            \n",
    "            # same origin destination pair\n",
    "            if node_row[\"OD\"].item() == curr_row[\"OD\"].item():\n",
    "                \n",
    "                # occur on different days\n",
    "                if node_row[\"date\"].item() != curr_row[\"date\"].item():\n",
    "                    \n",
    "                    # similar scheduled initial departure time\n",
    "                    curr_depart_time = pd.to_datetime(curr_row[\"departure_sched\"], format=\"%H%M\").item()\n",
    "                    if t1 <= curr_depart_time <= t2:\n",
    "                        \n",
    "                        # similar number of stops\n",
    "                        if node_stops-stop_delta <= curr_row[\"stops_in_journey\"].item() <= node_stops+stop_delta:\n",
    "                            # associate row j with node\n",
    "                            df_tmp.at[j, \"node_idx\"] = node_count\n",
    "                            df_save = df_save.append(curr_row)\n",
    "                            curr_node_count += 1\n",
    "                            \n",
    "        # remove rows that are assigned to nodes\n",
    "        df_tmp = df_tmp.loc[df_tmp[\"node_idx\"] == -1]\n",
    "        df_tmp = df_tmp.reset_index(drop=True)\n",
    "        node_count += 1\n",
    "        \n",
    "    # TODO a route is completely characterized by it's \"starting\" row,\n",
    "    ## remove all rows except starting rows and assign node to the rest of the data using RID\n",
    "    # TODO reconstruct the full data with node index using df_save, df, and RID\n",
    "    return df_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T19:38:47.137258Z",
     "start_time": "2020-02-27T19:37:57.464488Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nodes = create_nodes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T19:38:47.143859Z",
     "start_time": "2020-02-27T19:38:47.138435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_nodes[\"departure_sched\"] = df_nodes[\"departure_sched\"].astype(\"str\")\n",
    "df_nodes[\"departure_sched_datetime\"] = pd.to_datetime(\"1900-01-01\" + \" \" + df_nodes[\"departure_sched\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T19:38:47.150950Z",
     "start_time": "2020-02-27T19:38:47.144906Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:  55\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Nodes: \", len(np.unique(df_nodes[\"node_idx\"])))\n",
    "# how many unique routes do we get using this formulation?\n",
    "## around 50-70 depending on stop_delta and time_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.unique(curr_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_nodes = max(df_nodes[\"node_idx\"])\n",
    "plot = plt.figure(figsize=(16, 9))\n",
    "fig = plt.subplot()\n",
    "cmap=cm.get_cmap(\"plasma\")\n",
    "df_nodes[\"departure_sched\"] = df_nodes[\"departure_sched\"].astype(\"int\")\n",
    "xticks = []\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    color_idx = i / n_nodes\n",
    "    \n",
    "    rows = df_nodes.loc[df_nodes[\"node_idx\"] == i]\n",
    "    curr_depart = rows[\"departure_sched\"]\n",
    "    curr_stops = rows[\"stops_in_journey\"]\n",
    "    plt.scatter(curr_depart, curr_stops, c=[cmap(color_idx)], s=50)\n",
    "    \n",
    "#     center_x = (np.ptp(curr_depart) / 2) + min(curr_depart)\n",
    "#     center_y = (np.ptp(curr_stops) / 2) + min(curr_stops)\n",
    "#     rx = max(2*(max(curr_depart) - center_x), 5)\n",
    "#     ry = max(2*(max(curr_stops) - center_y), 3)\n",
    "\n",
    "#     ellipse = matplotlib.patches.Ellipse((center_x, center_y), rx, ry, alpha = 0.25)\n",
    "#     ellipse.set_facecolor(cmap(color_idx))\n",
    "#     fig.add_artist(ellipse)\n",
    "\n",
    "plt.xlabel(\"Initial Departure Time\")\n",
    "plt.ylabel(\"Total Number of Stops\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# how many times does each route run using this formulation?\n",
    "runs_per_node = []\n",
    "for i in range(n_nodes):\n",
    "    df_tmp = df_nodes.loc[df_nodes[\"node_idx\"] == i]\n",
    "    runs_per_node.append(len(df_tmp))\n",
    "\n",
    "\n",
    "fig = plt.subplots(figsize=(16, 9))\n",
    "nodes_x = np.arange(0, n_nodes, 1)\n",
    "plt.xlabel(\"Node Index\")\n",
    "plt.ylabel(\"Runs per Node\")\n",
    "plt.title(\"Runs per Node during Data Period\")\n",
    "plt.plot(nodes_x, runs_per_node)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# each unique route certainly has a \"starting\" station, so reduce the problem space by only considering these rows\n",
    "df_test = df.loc[df[\"arrival_actual\"] == \"starting\"]\n",
    "df_test[\"OD\"] = df[\"station_origin\"] + df[\"station_destination\"]\n",
    "\n",
    "print(len(df_test))\n",
    "\n",
    "unique_rid = np.unique(df[\"RID\"])\n",
    "n_unique_rid = len(unique_rid)\n",
    "print(n_unique_rid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_od = df_test.loc[df_test[\"OD\"] == \"BANPAD\"]\n",
    "unique_stops = np.unique(df[\"stops_in_journey\"])\n",
    "df_stops = df_od.loc[df_od[\"stops_in_journey\"] == 22]\n",
    "\n",
    "# n_unique_stops = len(unique_stops)\n",
    "# print(unique_stops)\n",
    "# print(n_unique_stops)\n",
    "\n",
    "\n",
    "# get unique set of dates from for \"close\" initial departure times, check if there are any matches \n",
    "# (if so, then the routes are unique and deserve to be separate nodes on the graph)\n",
    "# TODO how to come up with the candidate set of \"close\" initial departure times?\n",
    "## probably check if they're within 10 minutes radius of each other?\n",
    "dep_list = [\"0604\", \"0608\", \"0609\"]\n",
    "# dep_list = ['0604' '0608' '0609' '0625' '0703' '0728' '0935']\n",
    "\n",
    "date_list = []\n",
    "\n",
    "for i in range(len(dep_list)):\n",
    "    dep_time = dep_list[i]\n",
    "    df_tmp = df_stops.loc[df_stops[\"departure_sched\"] == dep_time]\n",
    "    dates = np.ndarray.tolist(np.unique(df_tmp[\"date\"]))\n",
    "    for j in dates:\n",
    "        date_list.append(j)\n",
    "\n",
    "if len(date_list) == len(set(date_list)):\n",
    "    print(\"they're all unique\")\n",
    "    # these times should be considered the same route\n",
    "\n",
    "\n",
    "# unique_dep = np.unique(df_stops[\"departure_sched\"])\n",
    "# n_unique_dep = len(unique_dep)\n",
    "# print(n_unique_dep)\n",
    "# print(unique_dep)\n",
    "\n",
    "\n",
    "\n",
    "# df_date = df_stops.loc[df_stops[\"date\"] == \"2016-03-03\"]\n",
    "# print(len(df_date))\n",
    "\n",
    "# df_start = df_stops.loc[df_stops[\"departure_sched\"] == \"0625\"]\n",
    "# print(len(df_start))\n",
    "# print(len(np.unique(df_start[\"date\"])))\n",
    "\n",
    "# certainly, a trains departing their first station at 0604 and 0625 are unique routes b/c they are both \n",
    "# run on the same day and could even cause delays for each other\n",
    "\n",
    "# however, are 0604, 0608, 0609 ever run on the same day?  if not, the scheduled departure was changed for \n",
    "# this route, but it's still considered the same route\n",
    "\n",
    "# what is a good cutoff time to consider two routes different from their initial departure?  \n",
    "# probably 10 minutes or so b/c the same station isn't going to have the exact same route leave 10 minutes apart\n",
    "# that would just be wasteful unless there's a fucking huge amount of traffic\n",
    "\n",
    "# # this route is the first of the day to run through this particular set of stops\n",
    "# # what about 0935? this is the second route of the day to run through this particular set of stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_604 = df_stops.loc[df_stops[\"departure_sched\"] == \"0609\"]\n",
    "print(len(df_604))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pd pivot ?\n",
    "# date_list = [\"2016-01-03\", \"2016-01-04\",\"2016-01-05\", \"2016-01-06\", \"2016-01-07\", \"2016-01-08\", \"2016-01-09\", \"2016-01-10\", \"2016-01-11\", \"2016-01-12\"]\n",
    "# for i in date_list:\n",
    "#     df_test = df.loc[df[\"date\"] == i]\n",
    "    \n",
    "\n",
    "# # date_list = [\"2016-01-05\"]\n",
    "# for i in date_list:\n",
    "#     df_test = df.loc[df[\"date\"] == i]\n",
    "#     unique_rid = np.unique(df_test[\"RID\"])\n",
    "#     unique_id = np.unique(df_test[\"train_id\"])\n",
    "# #     print(unique_rid)\n",
    "#     print(len(unique_rid) == len(unique_id))\n",
    "# #     print(unique_id)\n",
    "# #     print(len(unique_id))\n",
    "\n",
    "\n",
    "# RID gives a unique route for each day, but it is not clear if this transfers between days\n",
    "# i.e. will day_1_train_id_1 == day_2_train_id_1 for the same OD stations?\n",
    "# how many examples of the same route being run do we have during the data period t?\n",
    "\n",
    "\n",
    "# # see if train ids repeat within the dataset\n",
    "# #TODO i'm sure the result of this means something, but what?\n",
    "# for i in df[\"train_id\"]:\n",
    "#     df_test = df.loc[df[\"train_id\"] == i]\n",
    "#     unique_routes = np.unique(df_test[\"RID\"])\n",
    "#     if len(unique_routes) > 1:\n",
    "#         print(len(unique_routes))\n",
    "    \n",
    "#     print(len(df_test))\n",
    "        \n",
    "#         print(df.loc[df[\"train_id\"] == i][\"departure_sched\"])\n",
    "\n",
    "# train_id_list = [\"1279959\"]\n",
    "# for i in train_id_list:\n",
    "#     df_test = df.loc[df[\"train_id\"] == i]\n",
    "# #     print(len(df_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:55:43.007269Z",
     "start_time": "2020-01-15T16:55:42.951454Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # number of unique routes are run each day of the year (i.e. with unique station_origin and station_destination)\n",
    "# datetime_start = min(df[\"arrival_actual_datetime\"])\n",
    "# datetime_end = max(df[\"arrival_actual_datetime\"])\n",
    "# num_days = (datetime_end - datetime_start).days\n",
    "# day_arr = np.arange(start=0, stop=num_days, step=1)\n",
    "# train_arr = np.zeros(num_days)\n",
    "\n",
    "# for i in range(num_days):\n",
    "#     curr_year = (datetime_start + pd.Timedelta(i, unit=\"d\")).year\n",
    "#     curr_month = \"{:02d}\".format((datetime_start + pd.Timedelta(i, unit=\"d\")).month)\n",
    "#     curr_day = \"{:02d}\".format((datetime_start + pd.Timedelta(i, unit=\"d\")).day)\n",
    "#     curr_date = \"{}-{}-{}\".format(curr_year, curr_month, curr_day)\n",
    "#     df_tmp = df.loc[df[\"date\"] == curr_date]\n",
    "    \n",
    "#     # \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:48:49.567395Z",
     "start_time": "2020-01-15T16:48:46.852848Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of trains running each day of the year\n",
    "datetime_start = min(df[\"arrival_actual_datetime\"])\n",
    "datetime_end = max(df[\"arrival_actual_datetime\"])\n",
    "num_days = (datetime_end - datetime_start).days\n",
    "day_arr = np.arange(start=0, stop=num_days, step=1)\n",
    "train_arr = np.zeros(num_days)\n",
    "\n",
    "for i in range(num_days):\n",
    "    curr_year = (datetime_start + pd.Timedelta(i, unit=\"d\")).year\n",
    "    curr_month = \"{:02d}\".format((datetime_start + pd.Timedelta(i, unit=\"d\")).month)\n",
    "    curr_day = \"{:02d}\".format((datetime_start + pd.Timedelta(i, unit=\"d\")).day)\n",
    "    curr_date = \"{}-{}-{}\".format(curr_year, curr_month, curr_day)\n",
    "    df_tmp = df.loc[df[\"date\"] == curr_date]\n",
    "    \n",
    "    # the RIDs of the particular trains running that day\n",
    "    trains_running = np.unique(df_tmp[\"RID\"])\n",
    "    train_arr[i] = len(trains_running)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:50:21.257035Z",
     "start_time": "2020-01-15T16:50:21.094467Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # the RID consists of the date, followed by another number.  \n",
    "# # What does that other number signify?  I don't think it is a unique identifier for the particular train\n",
    "# # df[\"RID\"] = df[\"RID\"].astype(str)\n",
    "# # df[\"train_id\"] = df[\"RID\"].str.slice(8, -1)\n",
    "# # num_trains = len(np.unique(df[\"train_id\"]))\n",
    "# # num_trains\n",
    "\n",
    "# # it looks like there is a weird data imbalance, each train \n",
    "# plt.plot(day_arr, train_arr)\n",
    "# plt.xlabel(\"Day of Year\")\n",
    "# plt.ylabel(\"Number of Unique Trains\")\n",
    "# plt.show()\n",
    "\n",
    "# #TODO remove the days when 0 trains are running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T22:47:42.643244Z",
     "start_time": "2020-01-14T22:47:42.356568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make histogram of arrival delay\n",
    "hist = plt.hist(df[\"arrival_delay_minutes\"], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T22:47:44.468722Z",
     "start_time": "2020-01-14T22:47:44.333086Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a CDF (cumulative distribution function) of arrival delay\n",
    "x = np.array(df[\"arrival_delay_minutes\"])\n",
    "x = np.sort(x)\n",
    "N = len(x)\n",
    "y = np.array(range(N)) / float(N)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
